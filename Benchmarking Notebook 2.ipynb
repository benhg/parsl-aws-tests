{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import parsl\n",
    "from parsl import *\n",
    "from ipyparallel import Client\n",
    "import aws\n",
    "\n",
    "\n",
    "executor = parsl.executors.ipp.IPyParallelExecutor()\n",
    "dfk = DataFlowKernel(executor)\n",
    "provider = aws.EC2Provider('providerconf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "@App('python', dfk)\n",
    "def mc_pi(n):\n",
    "    import random\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) <= 1:\n",
    "            count += 1\n",
    "    return count/n\n",
    "\n",
    "def mc_pi_serial(n):\n",
    "    import random\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) <= 1:\n",
    "            count += 1\n",
    "    return count/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%timeit est_pi = mc_pi_serial(1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterOptions = [1,2,4,8,16]\n",
    "allres = []\n",
    "for q, size in enumerate(clusterOptions):\n",
    "    rates = []\n",
    "    increase = (size - clusterOptions[q-1]) if q > 0 else 1\n",
    "    provider.scale_out(increase)\n",
    "    print(increase)\n",
    "    time.sleep(180)\n",
    "    for i in range(10):\n",
    "        time.sleep(0.5)\n",
    "        res = []\n",
    "        begin = time.time()\n",
    "        results = [mc_pi(n) for n in [250000]*32]\n",
    "        pi = sum([result.result() for result in results])/8\n",
    "        end = time.time()\n",
    "        total = (end-begin)\n",
    "        print(pi,total)\n",
    "        res.append(total)\n",
    "    allres.append(np.mean(res))\n",
    "print(allres)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@App('python', dfk)\n",
    "def parsl_test_app(sleeptime, in_data, out_data_size=0):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import os\n",
    "    time.sleep(sleeptime)\n",
    "    return np.random.rand(int(out_data_size))\n",
    "\n",
    "def test_latency(n):\n",
    "    fus = []\n",
    "    tic = time.time()\n",
    "    echo = lambda x: x\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        fus.append(parsl_test_app(0,[5],55))\n",
    "    toc = time.time()\n",
    "    fus[-1].result()\n",
    "    tac = time.time()\n",
    "    rt = tac-tic\n",
    "    sent = toc-tic\n",
    "    return sent, rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task throughput as a function of nodes\n",
    "# 1, 2, 4, 8, 16 t2.small. Do c4.large\n",
    "#provider.scale_in(10)\n",
    "allRates = []\n",
    "clusterOptions = [1,2,4,8,16]\n",
    "for i, size in enumerate(clusterOptions):\n",
    "    rates = []\n",
    "    increase = (size - clusterOptions[i-1]) if i > 0 else 1\n",
    "    print(increase)\n",
    "    provider.scale_out(increase)\n",
    "    time.sleep(180)\n",
    "    for n in [300,300,300,300,300,300,300]:\n",
    "        # short rest between tests\n",
    "        time.sleep(.5)\n",
    "        s, rt = test_latency(n)\n",
    "        rates.append(n/s)\n",
    "        print( \"%4i %6.1f %6.1f\" % (n,n/s, n/rt))\n",
    "    allRates.append(np.mean(rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allres = [0.96068835258483887,\n",
    " 0.47994661331176758,\n",
    " 0.26649975776672363,\n",
    " 0.2669832706451416,\n",
    " 0.26372933387756348]\n",
    "allRates = [1594.6386265752353, 1562.5417109307268, 1591.7190755992528, 1584.7605780185415, 1573.3746584762646]\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(clusterOptions, allRates, color='blue')\n",
    "ax1.set_ylabel(\"Tasks Submitted/sec\", color=\"blue\")\n",
    "ax1.set_xlabel(\"Nodes\", color=\"blue\")\n",
    "ax1.set_yticks(np.arange(500.,2000.,100.))\n",
    "ax1.set_ticklabels(np.arange(500.,2000.,100.))\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provider.scale_out(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate random 2D-patterns\n",
    "mu_vec = np.array([0,0])\n",
    "cov_mat = np.array([[1,0],[0,1]])\n",
    "x_2Dgauss = np.random.multivariate_normal(mu_vec, cov_mat, 10000)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "var = multivariate_normal(mean=[0,0], cov=[[1,0],[0,1]])\n",
    "print('actual probability density:', var.pdf([0,0]))\n",
    "\n",
    "@App('python', dfk)\n",
    "def parzen_estimation(x_samples, point_x, h):\n",
    "    import numpy as np\n",
    "    k_n = 0\n",
    "    for row in x_samples:\n",
    "        x_i = (point_x - row[:,np.newaxis]) / (h)\n",
    "        for row in x_i:\n",
    "            if np.abs(row) > (1/2):\n",
    "                break\n",
    "        else: # \"completion-else\"*\n",
    "            k_n += 1\n",
    "    return (h, (k_n / len(x_samples)) / (h**point_x.shape[1]))\n",
    "\n",
    "def parzen_estimation_s(x_samples, point_x, h):\n",
    "    k_n = 0\n",
    "    for row in x_samples:\n",
    "        x_i = (point_x - row[:,np.newaxis]) / (h)\n",
    "        for row in x_i:\n",
    "            if np.abs(row) > (1/2):\n",
    "                break\n",
    "        else: # \"completion-else\"*\n",
    "            k_n += 1\n",
    "    return (h, (k_n / len(x_samples)) / (h**point_x.shape[1]))\n",
    "\n",
    "def serial(samples, x, widths):\n",
    "    return [parzen_estimation_s(samples, x, w) for w in widths]\n",
    "\n",
    "def multiprocess(samples, x, widths):\n",
    "    results = [parzen_estimation(samples, x, w) for w in widths]\n",
    "    results = [p.result() for p in results]\n",
    "    results.sort()\n",
    "    return results\n",
    "\n",
    "widths = np.arange(0.1, 1.3, 0.1)\n",
    "point_x = np.array([[0],[0]])\n",
    "results = []\n",
    "\n",
    "results = multiprocess(x_2Dgauss, point_x, widths)\n",
    "\n",
    "for r in results:\n",
    "    print('h = %s, p(x) = %s' %(r[0], r[1]))\n",
    "\n",
    "\n",
    "widths = np.linspace(1.0, 1.2, 100)\n",
    "import timeit\n",
    "\n",
    "mu_vec = np.array([0,0])\n",
    "cov_mat = np.array([[1,0],[0,1]])\n",
    "n = 10000\n",
    "\n",
    "x_2Dgauss = np.random.multivariate_normal(mu_vec, cov_mat, n)\n",
    "\n",
    "benchmarks = []\n",
    "\n",
    "benchmarks.append(timeit.Timer('serial(x_2Dgauss, point_x, widths)',\n",
    "            'from __main__ import serial, x_2Dgauss, point_x, widths').timeit(number=1))\n",
    "\n",
    "benchmarks.append(timeit.Timer('multiprocess( x_2Dgauss, point_x, widths)',\n",
    "            'from __main__ import multiprocess, x_2Dgauss, point_x, widths').timeit(number=1))\n",
    "\n",
    "benchmarks.append(timeit.Timer('multiprocess( x_2Dgauss, point_x, widths)',\n",
    "            'from __main__ import multiprocess, x_2Dgauss, point_x, widths').timeit(number=1))\n",
    "\n",
    "benchmarks.append(timeit.Timer('multiprocess( x_2Dgauss, point_x, widths)',\n",
    "            'from __main__ import multiprocess, x_2Dgauss, point_x, widths').timeit(number=1))\n",
    "\n",
    "benchmarks.append(timeit.Timer('multiprocess( x_2Dgauss, point_x, widths)',\n",
    "            'from __main__ import multiprocess, x_2Dgauss, point_x, widths').timeit(number=1))\n",
    "\n",
    "import platform\n",
    "\n",
    "def print_sysinfo():\n",
    "\n",
    "    print('\\nPython version  :', platform.python_version())\n",
    "    print('compiler        :', platform.python_compiler())\n",
    "\n",
    "    print('\\nsystem     :', platform.system())\n",
    "    print('release    :', platform.release())\n",
    "    print('machine    :', platform.machine())\n",
    "    print('processor  :', platform.processor())\n",
    "    print('CPU count  :', mp.cpu_count())\n",
    "    print('interpreter:', platform.architecture()[0])\n",
    "    print('\\n\\n')\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_results():\n",
    "    bar_labels = ['serial', '2', '3', '4', '6']\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "    # plot bars\n",
    "    y_pos = np.arange(len(benchmarks))\n",
    "    plt.yticks(y_pos, bar_labels, fontsize=16)\n",
    "    bars = plt.barh(y_pos, benchmarks,\n",
    "             align='center', alpha=0.4, color='g')\n",
    "\n",
    "    # annotation and labels\n",
    "\n",
    "    for ba,be in zip(bars, benchmarks):\n",
    "        plt.text(ba.get_width() + 2, ba.get_y() + ba.get_height()/2,\n",
    "                '{0:.2%}'.format(benchmarks[0]/be),\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    plt.xlabel('time in seconds for n=%s' %n, fontsize=14)\n",
    "    plt.ylabel('number of processes', fontsize=14)\n",
    "    t = plt.title('Serial vs. Multiprocessing via Parzen-window estimation', fontsize=18)\n",
    "    plt.ylim([-1,len(benchmarks)+0.5])\n",
    "    plt.xlim([0,max(benchmarks)*1.1])\n",
    "    plt.vlines(benchmarks[0], -1, len(benchmarks)+0.5, linestyles='dashed')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
