{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pickle\n",
    "import aws\n",
    "from parsl import *\n",
    "import parsl\n",
    "provider = aws.EC2Provider('providerconf.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from ipyparallel import Client\n",
    "rc=Client()\n",
    "executor = parsl.executors.ipp.IPyParallelExecutor()\n",
    "dfk = DataFlowKernel(executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    time.sleep(10)\n",
    "    provider.scale_out(1)\n",
    "    start=time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            view = rc[:]\n",
    "            end = time.time()\n",
    "            times.append(end-start)\n",
    "            provider.scale_in(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times=[111,111,107.,104.26447439193726, 114.74069857597351,114.83456110954285,112.26447439193726, 118.74069857597351,113.83456110954285,119.26447439193726, 121.74069857597351,123.83456110954285,116.26447439193726, 108.74069857597351,123.83456110954285, 114.56703305244446, 117.43648338317871, 114.235]\n",
    "print(len(times))\n",
    "plt.hist(times, normed=True, bins=10, color='green')\n",
    "plt.title(\"Distribution of spin-up times\")\n",
    "plt.xlabel(\"Time until engine registration (sec)\")\n",
    "plt.ylabel(\"Relative frequency (total area: 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@App('python', dfk)\n",
    "def get_num(first, second):\n",
    "    return first + second \n",
    "\n",
    "def test_fibonacci(num = 5):\n",
    "    x1 = 0\n",
    "    x2 = 1\n",
    "    counter = 0\n",
    "    results = [ ]\n",
    "    results.append(0)\n",
    "    results.append(1)\n",
    "    while counter < num - 2:\n",
    "        counter += 1 \n",
    "        results.append(get_num(x1, x2))\n",
    "        temp = x2\n",
    "        x2 = get_num(x1, x2)\n",
    "        x1 = temp\n",
    "        results[-1].result()\n",
    "    for i in range(len(results)):\n",
    "        if type(results[i]) is int:\n",
    "            #print(results[i])\n",
    "            pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@App('python',dfk)\n",
    "def double(x):\n",
    "    return x*2\n",
    "\n",
    "\n",
    "def mapReduce(n):\n",
    "    tic=time.time()\n",
    "    jobs = []\n",
    "    for i in range(0,n):\n",
    "        jobs.extend([double(i)])\n",
    "    #result = sum(res.result() for res in jobs)\n",
    "    jobs[-1].result()\n",
    "    toc = time.time()\n",
    "    return toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapReduce(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 node 11.3sec #2engines: 9.254sec #3engines 11.4sec, 4engines 10.6sec\n",
    "tic = time.time()\n",
    "test_fibonacci(900)\n",
    "tac = time.time()\n",
    "diff = tac-tic\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@App('python', dfk)\n",
    "def parsl_test_app(sleeptime, in_data, out_data_size=0):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import os\n",
    "    time.sleep(sleeptime)\n",
    "    return np.random.rand(int(out_data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_latency(n):\n",
    "    fus = []\n",
    "    tic = time.time()\n",
    "    echo = lambda x: x\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        fus.append(parsl_test_app(0,[5],55))\n",
    "    toc = time.time()\n",
    "    fus[-1].result()\n",
    "    tac = time.time()\n",
    "    rt = tac-tic\n",
    "    sent = toc-tic\n",
    "    return sent, rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task throughput as a function of nodes\n",
    "# 1, 2, 4, 8, 16 t2.small. Do c4.large\n",
    "#provider.scale_in(10)\n",
    "allRates = []\n",
    "clusterOptions = [1,2,4,8,16]\n",
    "for i, size in enumerate(clusterOptions):\n",
    "    rates = []\n",
    "    increase = (size - clusterOptions[i-1]) if i > 0 else 1\n",
    "    print(increase)\n",
    "    #provider.scale_out(increase)\n",
    "    for n in [300,300,300,300,300,300]:\n",
    "        # short rest between tests\n",
    "        time.sleep(5)\n",
    "        s, rt = test_latency(n)\n",
    "        rates.append(n/s)\n",
    "        print( \"%4i %6.1f %6.1f\" % (n,n/s, n/rt))\n",
    "    allRates.append(np.mean(rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(clusterOptions, allRates)\n",
    "plt.plot(clusterOptions, allRates)\n",
    "plt.xlabel(\"nodes\")\n",
    "plt.ylabel(\"tasks/sec\")\n",
    "plt.plot()\n",
    "plt.yticks(range(500,2000,100))\n",
    "provider.scale_in(16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provider.scale_out(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task throughput as a function of nodes\n",
    "# 1, 2, 4, 8, 16 t2.small. Do c4.large\n",
    "rates1 = []\n",
    "tasks1 = []\n",
    "for n in [100,200,300,400,500,600,700,800,900,1000,2000,5000]:\n",
    "    # short rest between tests\n",
    "    time.sleep(5)\n",
    "    s = test_latency(n)\n",
    "    rates.append(n/s)\n",
    "    tasks.append(n)\n",
    "    print( \"%4i %6.1f %6.1f\" % (n,n/s, n/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(tasks1, rates1)\n",
    "plt.title(\"Job submit rate vs number of jobs (1 node) with C4.large instances\")\n",
    "plt.xlabel(\"jobs\")\n",
    "plt.ylabel(\"tasks/sec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_throughput(n):\n",
    "    fus=[]\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        a = parsl_test_app(0.8,5,0)\n",
    "        fus.append(a)\n",
    "    toc = time.time()  \n",
    "    fus[-1].result()\n",
    "    tac = time.time()\n",
    "    sent = toc-tic\n",
    "    roundtrip = tac-tic\n",
    "    return sent, roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provider.scale_in(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allRates1 = []\n",
    "clusterOptions = [1,2,4,8,16]\n",
    "for i, size in enumerate(clusterOptions):\n",
    "    increase = (size - clusterOptions[i-1]) if i > 0 else 1\n",
    "    print(increase)\n",
    "    #provider.scale_out(increase)\n",
    "    #time.sleep(300)\n",
    "    for n in [100,200,300,400,500,600,700,800,900,1000]:\n",
    "        rates = []\n",
    "        # short rest between tests\n",
    "        time.sleep(5)\n",
    "        s,rt = test_throughput(n)\n",
    "        rates.append(n/rt)\n",
    "        print( \"%4i %6.1f %6.1f\" % (n,n/s, n/rt))\n",
    "    allRates1.append(np.mean(rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(clusterOptions, allRates1)\n",
    "plt.title(\"Job throughput (completion) vs number of nodes with C4.large instances (1 ms jobs)\")\n",
    "plt.xlabel(\"nodes\")\n",
    "plt.ylabel(\"tasks/sec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_map(v,dt,n):\n",
    "    ts = [dt]*n\n",
    "    tic = time.time()\n",
    "    amr = v.map_async(time.sleep, ts)\n",
    "    toc = time.time()\n",
    "    amr.get()\n",
    "    tac = time.time()\n",
    "    sent = toc-tic\n",
    "    roundtrip = tac-tic\n",
    "    return sent, roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view = rc.load_balanced_view()\n",
    "n = len(rc.ids) * 16\n",
    "sizes = []\n",
    "rates = []\n",
    "for dt in np.logspace(-3,0,7):\n",
    "    time.sleep(0.5)\n",
    "    s,rt = test_map(view, dt, n)\n",
    "    print(\"%4ims %5.1f%%\" % (1000*dt, 1600*dt / rt))\n",
    "    sizes.append(1000*dt)\n",
    "    rates.append(1600*dt / rt)\n",
    "plt.plot(sizes, rates)\n",
    "plt.plot(sizes, rates)\n",
    "plt.title(\"CPU Utilization vs Task Completion Time (16 AWS c4.large nodes)\")\n",
    "plt.xlabel('Task Size (ms to completion)')\n",
    "plt.ylabel('Utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integrand(x):\n",
    "    return exp(-(x)**2)\n",
    "print(\"integrand(1) ={}\".format(integrand(1)))\n",
    "\n",
    "def integral(x):\n",
    "    return quad(integrand,0,x)[0]\n",
    "print (\"integral(1) ={}\".format(integral(1)))\n",
    "\n",
    "N = 1000\n",
    "%timeit -n 10 map(integral, range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = rc[:]\n",
    "print(\"# CPUs {}\".format(len(pool.client.ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pool.sync_imports():\n",
    "    from scipy.integrate import quad\n",
    "    from numpy import exp\n",
    "pool['integrand'] = integrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pool.map_async(integral, range(10)))\n",
    "%timeit -n 10 pool.map(integral, range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool.execute('import numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this runs on the engins\n",
    "def calc_pi_on_engines(n):\n",
    "    x = numpy.random.rand(n)\n",
    "    y = numpy.random.rand(n)\n",
    "    r = numpy.hypot(x, y)\n",
    "    return 4. * (r < 1.).sum() / n\n",
    "\n",
    "\n",
    "def calc_pi(n):\n",
    "    \"\"\"Estimate pi using IPython.parallel.\"\"\"\n",
    "    n_engines = n/len(view)\n",
    "    results = view.apply_sync(calc_pi_on_engines, n_engines)\n",
    "    return float(sum(results))/len(results)\n",
    "\n",
    "\n",
    "def main(N):\n",
    "    result, time = calc_pi(N)\n",
    "    print('time  : %3.4g\\nresult: %.7f' % (time, result))\n",
    "    client.purge_everything()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_throughput(v, n, s):\n",
    "    A = np.random.random(int(s/8)) # doubles are 8B\n",
    "    tic = time.time()\n",
    "    echo = lambda x: x\n",
    "    tic = time.time()\n",
    "    for i in range(n):\n",
    "        v.apply_async(echo, A)\n",
    "    toc = time.time()\n",
    "    v.wait()\n",
    "    tac = time.time()\n",
    "    sent = toc-tic\n",
    "    roundtrip = tac-tic\n",
    "    return sent, roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view = rc[:]\n",
    "n = 128\n",
    "throughput = []\n",
    "for sz in [1e1,1e2,1e3,1e4,1e5,5e5,1e6,2e6]:\n",
    "    # short rest between tests\n",
    "    time.sleep(1)\n",
    "    s,rt = test_throughput(view, n, int(sz))\n",
    "    throughput.append(1e-6*sz*n/rt)\n",
    "    print(\"%8f  %6.1f t/s  %6.1f t/s %9.3f Mbps\" % (sz,n/s,n/rt, 1e-6*sz*n/rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel(\"Task Size (input data size in bytes)\", color=\"blue\")\n",
    "plt.title(\"Network Throughput vs Task Input Data Size (4 AWS c4.large nodes)\")\n",
    "ax1.set_xscale('log')\n",
    "ax1.plot([1e1,1e2,1e3,1e4,1e5,5e5,1e6,2e6], throughput, color='blue')\n",
    "ax1.set_ylabel(\"Throughput (Mbps)\", color=\"blue\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=parsl_test_app(5,[5,6,7],55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(a.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provider.scale_out(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view = Client()[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provider = parsl.execution_provider.aws.EC2Provider('path/to/config')\n",
    "executor = parsl.executors.ipp.IPyParallelExecutor()\n",
    "dfk = DataFlowKernel(executor)\n",
    "@App('python', dfk)\n",
    "def parsl_app(n):\n",
    "    arbitrary_function()\n",
    "    return 0\n",
    "provider.scale_out(16)\n",
    "#parsl will automatically run the code on all workers it can find\n",
    "results = [parsl_app(n).result() for n in range(1,100,1)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
